#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½åŠ å·¥å†³ç­–ç³»ç»Ÿ
ç»“åˆ LightRAGã€å¤§æ¨¡å‹å’ŒåŠ å·¥å†³ç­–æ¨¡å—ï¼Œæä¾›æ™ºèƒ½çš„å·¥è‰ºå’Œåˆ€å…·æ¨è
"""

import asyncio
import configparser
import logging
import json
import re
from typing import Dict, List, Any, Optional, Tuple
from lightrag_retrieval import IntelligentRetriever
from machining_advisor import MachiningAdvisor


class IntelligentMachiningSystem:
    """æ™ºèƒ½åŠ å·¥å†³ç­–ç³»ç»Ÿ"""
    
    def __init__(self, config: configparser.ConfigParser):
        self.config = config
        self.logger = self._setup_logger()
        
        # åˆå§‹åŒ–å­ç³»ç»Ÿ
        self.retriever = IntelligentRetriever(config)
        self.advisor = MachiningAdvisor(config)
        
        # é—®é¢˜åˆ†ææ¨¡å¼
        self.analysis_patterns = {
            'feature_extraction': [
                r'(åœ†æŸ±é€šå­”|åœ†å½¢é€šå­”|çŸ©å½¢é€šå­”|åœ†æŸ±å‡¸å°|çŸ©å½¢å‡¹æ§½|åœ†å½¢ç›²å­”)',
                r'ç‰¹å¾ç±»å‹[æ˜¯ä¸º](.+?)(?:[ï¼Œ,]|$)',
                r'ç‰¹å¾[æ˜¯ä¸º](.+?)(?:[ï¼Œ,]|$)',
                r'å·¥ä»¶.*ç‰¹å¾.*[æ˜¯ä¸º](.+?)(?:[ï¼Œ,]|$)',
                r'æœ‰ä¸€ä¸ª(.+?)(?:[ï¼Œ,]|$)'
            ],
            'dimension_extraction': [
                r'ç›´å¾„(?:æ˜¯|ä¸º)?(\d+(?:\.\d+)?)mm',
                r'å­”ç›´å¾„(?:æ˜¯|ä¸º)?(\d+(?:\.\d+)?)mm',
                r'é•¿åº¦(?:æ˜¯|ä¸º)?(\d+(?:\.\d+)?)mm',
                r'å®½åº¦(?:æ˜¯|ä¸º)?(\d+(?:\.\d+)?)mm',
                r'é«˜åº¦(?:æ˜¯|ä¸º)?(\d+(?:\.\d+)?)mm',
                r'æ·±åº¦(?:æ˜¯|ä¸º)?(\d+(?:\.\d+)?)mm'
            ],
            'process_stage_extraction': [
                r'(ç²—åŠ å·¥|åŠç²¾åŠ å·¥|ç²¾åŠ å·¥|æ¸…æ ¹)',
                r'éœ€è¦(ç²—åŠ å·¥|åŠç²¾åŠ å·¥|ç²¾åŠ å·¥|æ¸…æ ¹)',
                r'è¿›è¡Œ(ç²—åŠ å·¥|åŠç²¾åŠ å·¥|ç²¾åŠ å·¥|æ¸…æ ¹)'
            ],
            'surface_type_extraction': [
                r'(å¹³é¢|å‚ç›´é¢|åœ†æŸ±é¢|é”¥é¢)',
                r'è¡¨é¢[æ˜¯ä¸º](å¹³é¢|å‚ç›´é¢|åœ†æŸ±é¢|é”¥é¢)',
                r'é¢[æ˜¯ä¸º](å¹³é¢|å‚ç›´é¢|åœ†æŸ±é¢|é”¥é¢)'
            ]
        }
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('IntelligentMachiningSystem')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            self.logger.info("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½åŠ å·¥å†³ç­–ç³»ç»Ÿ...")
            
            # åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ
            if not self.retriever.initialize():
                self.logger.error("LightRAGæ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
                return False
            
            # åˆå§‹åŒ–åŠ å·¥å†³ç­–ç³»ç»Ÿ
            if not self.advisor.connect_neo4j():
                self.logger.error("åŠ å·¥å†³ç­–ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
                return False
            
            self.logger.info("âœ… æ™ºèƒ½åŠ å·¥å†³ç­–ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            self.logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _extract_parameters_from_text(self, text: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–åŠ å·¥å‚æ•°"""
        parameters = {
            'feature_name': None,
            'surface_type': None,
            'process_stage': None,
            'dimensions': {}
        }
        
        # æå–ç‰¹å¾ç±»å‹
        for pattern in self.analysis_patterns['feature_extraction']:
            match = re.search(pattern, text)
            if match:
                feature_name = match.group(1).strip()
                # æ ‡å‡†åŒ–ç‰¹å¾åç§°
                feature_name = self._normalize_feature_name(feature_name)
                parameters['feature_name'] = feature_name
                break
        
        # æå–å°ºå¯¸ä¿¡æ¯
        for pattern in self.analysis_patterns['dimension_extraction']:
            matches = re.findall(pattern, text)
            for match in matches:
                if 'ç›´å¾„' in pattern:
                    parameters['dimensions']['diameter'] = float(match)
                elif 'é•¿åº¦' in pattern:
                    parameters['dimensions']['length'] = float(match)
                elif 'å®½åº¦' in pattern:
                    parameters['dimensions']['width'] = float(match)
                elif 'é«˜åº¦' in pattern:
                    parameters['dimensions']['height'] = float(match)
                elif 'æ·±åº¦' in pattern:
                    parameters['dimensions']['depth'] = float(match)
        
        # æå–å·¥åºé˜¶æ®µ
        for pattern in self.analysis_patterns['process_stage_extraction']:
            match = re.search(pattern, text)
            if match:
                parameters['process_stage'] = match.group(1) if match.groups() else match.group(0)
                break
        
        # æå–è¡¨é¢ç±»å‹
        for pattern in self.analysis_patterns['surface_type_extraction']:
            match = re.search(pattern, text)
            if match:
                parameters['surface_type'] = match.group(1) if match.groups() else match.group(0)
                break
        
        return parameters
    
    def _normalize_feature_name(self, feature_name: str) -> str:
        """æ ‡å‡†åŒ–ç‰¹å¾åç§°"""
        # ç‰¹å¾åç§°æ˜ å°„è¡¨ - æ˜ å°„åˆ°æ•°æ®åº“ä¸­å­˜åœ¨çš„æ ‡å‡†åç§°
        feature_mapping = {
            'åœ†å½¢é€šå­”': 'åœ†æŸ±é€šå­”',
            'åœ†å­”': 'åœ†æŸ±é€šå­”',
            'åœ†å½¢å­”': 'åœ†æŸ±é€šå­”',
            'çŸ©å½¢å­”': 'çŸ©å½¢é€šå­”',
            'æ–¹å­”': 'çŸ©å½¢é€šå­”',
            'åœ†å°': 'åœ†æŸ±å‡¸å°',
            'çŸ©å½¢æ§½': 'çŸ©å½¢å‡¹æ§½',
            'æ–¹æ§½': 'çŸ©å½¢å‡¹æ§½',
            'å‡¹æ§½': 'çŸ©å½¢å‡¹æ§½'
        }
        
        return feature_mapping.get(feature_name, feature_name)
    
    async def _analyze_question_with_llm(self, question: str) -> Dict[str, Any]:
        """ä½¿ç”¨å¤§æ¨¡å‹åˆ†æé—®é¢˜"""
        analysis_prompt = f"""
è¯·åˆ†æä»¥ä¸‹åŠ å·¥é—®é¢˜ï¼Œæå–å…³é”®å‚æ•°ï¼š

é—®é¢˜ï¼š{question}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "feature_name": "ç‰¹å¾åç§°ï¼ˆå¦‚ï¼šåœ†å½¢é€šå­”ã€çŸ©å½¢å‡¹æ§½ã€åœ†æŸ±å‡¸å°ç­‰ï¼‰",
    "surface_type": "è¡¨é¢ç±»å‹ï¼ˆå¦‚ï¼šplaneã€å‚ç›´é¢ã€åœ†æŸ±é¢ç­‰ï¼‰",
    "process_stage": "å·¥åºé˜¶æ®µï¼ˆå¦‚ï¼šç²—åŠ å·¥ã€åŠç²¾åŠ å·¥ã€ç²¾åŠ å·¥ã€æ¸…æ ¹ï¼‰",
    "dimensions": {{
        "diameter": "ç›´å¾„å€¼ï¼ˆæ•°å­—ï¼‰",
        "length": "é•¿åº¦å€¼ï¼ˆæ•°å­—ï¼‰",
        "width": "å®½åº¦å€¼ï¼ˆæ•°å­—ï¼‰",
        "height": "é«˜åº¦å€¼ï¼ˆæ•°å­—ï¼‰",
        "depth": "æ·±åº¦å€¼ï¼ˆæ•°å­—ï¼‰"
    }},
    "analysis_confidence": "åˆ†æç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰",
    "missing_parameters": ["ç¼ºå¤±çš„å‚æ•°åˆ—è¡¨"]
}}

æ³¨æ„ï¼š
1. å¦‚æœæŸä¸ªå‚æ•°æ— æ³•ä»é—®é¢˜ä¸­æå–ï¼Œè¯·è®¾ä¸ºnull
2. å°ºå¯¸å€¼åªä¿ç•™æ•°å­—ï¼Œä¸è¦å•ä½
3. ç‰¹å¾åç§°è¦ä½¿ç”¨æ ‡å‡†æœ¯è¯­
4. è¡¨é¢ç±»å‹ä¼˜å…ˆä½¿ç”¨"plane"è¡¨ç¤ºå¹³é¢
"""
        
        try:
            # ä½¿ç”¨LightRAGçš„LLMæ¥å£
            response = await self.retriever.llm_client.call_llm(analysis_prompt)
            
            # å°è¯•è§£æJSONå“åº”
            if response and isinstance(response, str):
                # æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    analysis_result = json.loads(json_str)
                    return analysis_result
            
            self.logger.warning("LLMåˆ†æç»“æœæ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨è§„åˆ™æå–")
            return {}
            
        except Exception as e:
            self.logger.error(f"LLMåˆ†æå¤±è´¥: {e}")
            return {}
    
    def _infer_missing_parameters(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨æ–­ç¼ºå¤±çš„å‚æ•°"""
        # å¦‚æœæœ‰ç›´å¾„ä¿¡æ¯ï¼Œå¯ä»¥æ¨æ–­é•¿åº¦å’Œå®½åº¦
        if 'diameter' in parameters['dimensions'] and parameters['dimensions']['diameter']:
            diameter = parameters['dimensions']['diameter']
            if not parameters['dimensions'].get('length'):
                parameters['dimensions']['length'] = diameter
            if not parameters['dimensions'].get('width'):
                parameters['dimensions']['width'] = diameter
        
        # é»˜è®¤å·¥åºé˜¶æ®µ
        if not parameters['process_stage']:
            parameters['process_stage'] = 'ç²—åŠ å·¥'  # é»˜è®¤ç²—åŠ å·¥
        
        # é»˜è®¤è¡¨é¢ç±»å‹
        if not parameters['surface_type']:
            parameters['surface_type'] = 'plane'  # é»˜è®¤å¹³é¢
        
        # é»˜è®¤æ·±åº¦/é«˜åº¦
        if not parameters['dimensions'].get('height') and not parameters['dimensions'].get('depth'):
            if 'diameter' in parameters['dimensions']:
                # å¯¹äºå­”ç±»ç‰¹å¾ï¼Œé»˜è®¤æ·±åº¦ä¸ºç›´å¾„çš„2å€
                parameters['dimensions']['height'] = parameters['dimensions']['diameter'] * 2
            else:
                parameters['dimensions']['height'] = 10.0  # é»˜è®¤é«˜åº¦
        elif parameters['dimensions'].get('depth') and not parameters['dimensions'].get('height'):
            parameters['dimensions']['height'] = parameters['dimensions']['depth']
        
        return parameters
    
    async def _get_knowledge_context(self, question: str, parameters: Dict[str, Any]) -> str:
        """è·å–ç›¸å…³çŸ¥è¯†ä¸Šä¸‹æ–‡"""
        try:
            # æ„å»ºçŸ¥è¯†æŸ¥è¯¢
            knowledge_queries = []
            
            if parameters['feature_name']:
                knowledge_queries.append(f"{parameters['feature_name']}çš„åŠ å·¥å·¥è‰º")
            
            if parameters['process_stage']:
                knowledge_queries.append(f"{parameters['process_stage']}å·¥è‰ºå‚æ•°")
            
            # æŸ¥è¯¢ç›¸å…³çŸ¥è¯†
            all_context = []
            for query in knowledge_queries:
                context = await self.retriever._get_knowledge_context(query)
                if context:
                    all_context.append(context)
            
            return "\n\n".join(all_context)
            
        except Exception as e:
            self.logger.error(f"è·å–çŸ¥è¯†ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return ""
    
    async def process_machining_question(self, question: str) -> Dict[str, Any]:
        """å¤„ç†åŠ å·¥é—®é¢˜çš„ä¸»è¦æ–¹æ³•"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†é—®é¢˜: {question}")
            
            # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨è§„åˆ™æå–åŸºæœ¬å‚æ•°
            rule_parameters = self._extract_parameters_from_text(question)
            self.logger.info(f"è§„åˆ™æå–å‚æ•°: {rule_parameters}")
            
            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨LLMå¢å¼ºåˆ†æ
            llm_parameters = await self._analyze_question_with_llm(question)
            self.logger.info(f"LLMåˆ†æå‚æ•°: {llm_parameters}")
            
            # ç¬¬ä¸‰æ­¥ï¼šåˆå¹¶å’Œä¼˜åŒ–å‚æ•°
            final_parameters = self._merge_parameters(rule_parameters, llm_parameters)
            final_parameters = self._infer_missing_parameters(final_parameters)
            self.logger.info(f"æœ€ç»ˆå‚æ•°: {final_parameters}")
            
            # ç¬¬å››æ­¥ï¼šè·å–çŸ¥è¯†ä¸Šä¸‹æ–‡
            knowledge_context = await self._get_knowledge_context(question, final_parameters)
            
            # ç¬¬äº”æ­¥ï¼šä½¿ç”¨åŠ å·¥å†³ç­–ç³»ç»Ÿè·å–æ¨è
            machining_recommendation = None
            if (final_parameters['feature_name'] and 
                final_parameters['dimensions'].get('length') and 
                final_parameters['dimensions'].get('width') and 
                final_parameters['dimensions'].get('height')):
                
                machining_recommendation = self.advisor.get_machining_recommendation(
                    feature_name=final_parameters['feature_name'],
                    surface_type=final_parameters['surface_type'],
                    process_stage=final_parameters['process_stage'],
                    length=final_parameters['dimensions']['length'],
                    width=final_parameters['dimensions']['width'],
                    height=final_parameters['dimensions']['height']
                )
            
            # ç¬¬å…­æ­¥ï¼šç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            final_answer = await self._generate_intelligent_answer(
                question, final_parameters, knowledge_context, machining_recommendation
            )
            
            return final_answer
            
        except Exception as e:
            self.logger.error(f"å¤„ç†é—®é¢˜å¤±è´¥: {e}")
            return {
                "answer": f"å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "confidence": 0.0,
                "error": str(e)
            }
    
    def _merge_parameters(self, rule_params: Dict[str, Any], llm_params: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶è§„åˆ™æå–å’ŒLLMåˆ†æçš„å‚æ•°"""
        merged = rule_params.copy()
        
        if llm_params:
            # LLMç»“æœä¼˜å…ˆçº§æ›´é«˜
            for key in ['feature_name', 'surface_type', 'process_stage']:
                if llm_params.get(key) and not merged.get(key):
                    merged[key] = llm_params[key]
            
            # åˆå¹¶å°ºå¯¸ä¿¡æ¯
            if llm_params.get('dimensions'):
                for dim_key, dim_value in llm_params['dimensions'].items():
                    if dim_value and not merged['dimensions'].get(dim_key):
                        merged['dimensions'][dim_key] = float(dim_value)
        
        return merged
    
    async def _generate_intelligent_answer(self, question: str, parameters: Dict[str, Any], 
                                         knowledge_context: str, machining_recommendation: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½ç­”æ¡ˆ"""
        try:
            # ç”Ÿæˆè§„èŒƒåŒ–çš„ç®€æ´ç­”æ¡ˆ
            answer = self._generate_standardized_answer(machining_recommendation)
            
            return {
                "answer": answer,
                "confidence": 0.85,
                "sources": ["LightRAGçŸ¥è¯†å›¾è°±", "åŠ å·¥å†³ç­–ç³»ç»Ÿ", "æ´¾æ¬§äº‘LLM"],
                "parameters": parameters,
                "machining_recommendation": machining_recommendation,
                "knowledge_context": knowledge_context
            }
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ™ºèƒ½ç­”æ¡ˆå¤±è´¥: {e}")
            return {
                "answer": f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {str(e)}",
                "confidence": 0.0,
                "error": str(e)
            }
    
    def _generate_standardized_answer(self, machining_recommendation: Dict[str, Any]) -> str:
        """ç”Ÿæˆè§„èŒƒåŒ–çš„ç­”æ¡ˆæ ¼å¼"""
        if not machining_recommendation:
            return "æ¨èæ¨¡æ¿IDï¼šæ—   æ¨èåŠ å·¥å·¥è‰ºï¼šæ—   æ¨èåˆ€å…·IDï¼šæ— "
        
        # è·å–æ¨èæ¨¡æ¿ID
        process_templates = machining_recommendation.get('process_templates', [])
        template_id = process_templates[0].get('template_id') if process_templates else "æ— "
        
        # è·å–æ¨èåŠ å·¥å·¥è‰º
        process_type = process_templates[0].get('process_type') if process_templates else "æ— "
        
        # è·å–æ¨èåˆ€å…·ID
        suitable_tools = machining_recommendation.get('suitable_tools', [])
        tool_id = suitable_tools[0].get('tool_id') if suitable_tools else "æ— "
        
        return f"æ¨èæ¨¡æ¿IDï¼š{template_id}  æ¨èåŠ å·¥å·¥è‰ºï¼š{process_type}  æ¨èåˆ€å…·IDï¼š{tool_id}"
    
    def _generate_simple_id_answer(self, machining_recommendation: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€æ´çš„IDç­”æ¡ˆ"""
        if not machining_recommendation:
            return "âŒ æ— æ³•æä¾›æ¨èIDï¼Œæœªæ‰¾åˆ°åŒ¹é…çš„å·¥è‰ºå’Œåˆ€å…·ã€‚"
        
        answer_parts = []
        
        # å·¥è‰ºæ¨¡æ¿ID
        process_templates = machining_recommendation.get('process_templates', [])
        if process_templates:
            template_ids = [t.get('template_id') for t in process_templates]
            answer_parts.append(f"**å·¥è‰ºæ¨¡æ¿ID**: {', '.join(template_ids)}")
        else:
            answer_parts.append("**å·¥è‰ºæ¨¡æ¿ID**: æœªæ‰¾åˆ°")
        
        # åˆ€å…·ID
        suitable_tools = machining_recommendation.get('suitable_tools', [])
        if suitable_tools:
            tool_id = suitable_tools[0].get('tool_id')
            answer_parts.append(f"**åˆ€å…·ID**: {tool_id}")
        else:
            answer_parts.append("**åˆ€å…·ID**: æœªæ‰¾åˆ°")
        
        return "\n".join(answer_parts)
    
    def close(self):
        """å…³é—­ç³»ç»Ÿ"""
        if hasattr(self.retriever, 'neo4j_retriever'):
            self.retriever.neo4j_retriever.close()
        if hasattr(self.advisor, 'close'):
            self.advisor.close()


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ¤– æ™ºèƒ½åŠ å·¥å†³ç­–ç³»ç»Ÿ")
    print("=" * 80)
    print("ç»“åˆ LightRAGã€å¤§æ¨¡å‹å’ŒåŠ å·¥å†³ç­–ï¼Œæä¾›æ™ºèƒ½çš„å·¥è‰ºå’Œåˆ€å…·æ¨è")
    print()
    
    # åŠ è½½é…ç½®
    config = configparser.ConfigParser()
    config.read("config.ini", encoding='utf-8')
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = IntelligentMachiningSystem(config)
    
    try:
        if not await system.initialize():
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        # æµ‹è¯•é—®é¢˜
        test_questions = [
            "æˆ‘ç°åœ¨æœ‰ä¸€ä¸ªå·¥ä»¶ï¼Œä»–çš„åœ†æŸ±å‡¸å°ç²¾åŠ å·¥ï¼Œç›´å¾„12mmï¼Œé«˜åº¦6mmï¼Œç”¨ä»€ä¹ˆåŠ å·¥å·¥è‰ºå’Œåˆ€å…·ï¼Ÿ"
        ]
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ æµ‹è¯•é—®é¢˜ {i}")
            print(f"{'='*60}")
            print(f"é—®é¢˜: {question}")
            print("\næ­£åœ¨åˆ†æå’Œå¤„ç†...")
            
            result = await system.process_machining_question(question)
            
            print(f"\nğŸ¯ å›ç­”:")
            print(result['answer'])
            print(f"\nğŸ“Š ç½®ä¿¡åº¦: {result['confidence']}")
            print(f"ğŸ“š æ•°æ®æº: {', '.join(result.get('sources', []))}")
        
        print(f"\n{'='*80}")
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
    finally:
        system.close()


if __name__ == "__main__":
    asyncio.run(main())